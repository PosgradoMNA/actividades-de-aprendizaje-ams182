{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment01.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PosgradoMNA/actividades-de-aprendizaje-ams182/blob/main/segundo%20curso/assignment02_A01104775.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzUSMM79NR9P"
      },
      "outputs": [],
      "source": [
        "#Resumen de actividades semana 4\n",
        "\n",
        "# Alejandro Munguia Salazar A01104775\n",
        "\n",
        "# Semana 4: Data Analysis with Python (IBM) \n",
        "# Mod 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preproceso: acción de mapear o modificar la data cruda para prerparla para ser usada\n",
        "\n",
        "******************************\n",
        "Missing values: \n",
        "******************************\n",
        "\n",
        "datos faltantes, Nan, se sugiere:\n",
        "1.- regresar a la fuente por la info faltante\n",
        "2.- Si no hay mucho eliminar el registro con la info  \n",
        "3.- Se puede emplear alguna tecnica para completar la data para no perder info pero es menos preciso por ejemplo con la media, no siempre se puede con las variables categoricas para ellas hay mejoeres técnicas como la moda\n",
        "\n",
        "dropna() eliminar filas o col con el na, o df.replace() para reemplazarlos\n",
        "\n",
        "para reemplazar con la media: primero se calcula y luego se reemplaza:\n",
        "\n",
        "mean = df['col'].mean()\n",
        "df['col'].replace(np.nan, mean)\n",
        "\n",
        "4.- o simplemente dejarla como info vacia\n",
        "\n",
        "\n",
        "******************************\n",
        "Nomalizacion\n",
        "******************************\n",
        "\n",
        "Cunado las variables tienen difernetes escalas pueden provocar que la influencia de estas aumente o disminuya en el modelo, por eso se sugiere que las variables tengan una escala parecida.\n",
        "\n",
        "1.- simple feature scaling:\n",
        "\n",
        "x_nueva = x_vieja / max(x_vieja)\n",
        "\n",
        "2.- min_max:\n",
        "\n",
        "x_nueva =  ( x_vieja - min(x_vieja) ) / ( max(x_vieja) - min(x_vieja) )\n",
        "\n",
        "3.- Z-score\n",
        "\n",
        "x_nueva = ( x_vieja - Media ) / std\n",
        "\n",
        "\n",
        "******************************\n",
        "Binning (de numerica a categórica)\n",
        "******************************\n",
        "\n",
        "Agrupar una variable para que sea mas facil de leer, por ejemplo en la base el precio de los coches se agrupa en bajo, medio o alto\n",
        "\n",
        "bins = np.linspace(min(col),max(col),numero_de_bins)\n",
        "\n",
        "group_names = [ \"cat1\", \"cat2\", \"cat3\"]\n",
        "\n",
        "df[\"col_binned\"] = pd.cut(df[col],bins,label = group_names, include_lowest= True)\n",
        "\n",
        "******************************\n",
        "De categórica a numérica\n",
        "******************************\n",
        "\n",
        "La mayoria de los modelos no peuden tomar objetos como entrada, deben ser numericos\n",
        "\n",
        "pd.get_dummies(df['col'])"
      ],
      "metadata": {
        "id": "4jhGsN5hKt1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "from matplotlib import pyplot\n"
      ],
      "metadata": {
        "id": "O7yjJJALKwMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/Data%20files/auto.csv\"\n",
        "\n",
        "headers = [\"symboling\",\"normalized-losses\",\"make\",\"fuel-type\",\"aspiration\", \"num-of-doors\",\"body-style\",\n",
        "         \"drive-wheels\",\"engine-location\",\"wheel-base\", \"length\",\"width\",\"height\",\"curb-weight\",\"engine-type\",\n",
        "         \"num-of-cylinders\", \"engine-size\",\"fuel-system\",\"bore\",\"stroke\",\"compression-ratio\",\"horsepower\",\n",
        "         \"peak-rpm\",\"city-mpg\",\"highway-mpg\",\"price\"]\n",
        "\n",
        "df = pd.read_csv(filename, names = headers)"
      ],
      "metadata": {
        "id": "3qX7bbQyKxoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace \"?\" to NaN\n",
        "df.replace(\"?\", np.nan, inplace = True)\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "pQRiwA0eKzMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().any() #hay nulos en normalized-losses, num-of-doors, bore, stroke.... y todas con true"
      ],
      "metadata": {
        "id": "Hcq9pct-K0rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_data = df.isnull()\n",
        "for column in missing_data.columns.values.tolist():\n",
        "    print(column)\n",
        "    print (missing_data[column].value_counts())\n",
        "    print(\"\")   \n",
        "    \n",
        "#Los true son los datos perdidos "
      ],
      "metadata": {
        "id": "AN_8_qQRK31V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***********************************\n",
        "Entonces en resumen y por hacer:\n",
        "\n",
        "\n",
        "Based on the summary above, each column has 205 rows of data and seven of the columns containing missing data:\n",
        "\n",
        "    \"normalized-losses\": 41 missing data\n",
        "    \"num-of-doors\": 2 missing data\n",
        "    \"bore\": 4 missing data\n",
        "    \"stroke\" : 4 missing data\n",
        "    \"horsepower\": 2 missing data\n",
        "    \"peak-rpm\": 2 missing data\n",
        "    \"price\": 4 missing data\n",
        "\n",
        "Deal with missing data\n",
        "How to deal with missing data?\n",
        "\n",
        "    Drop data\n",
        "    a. Drop the whole row\n",
        "    b. Drop the whole column\n",
        "    Replace data\n",
        "    a. Replace it by mean\n",
        "    b. Replace it by frequency\n",
        "    c. Replace it based on other functions\n",
        "\n",
        "Whole columns should be dropped only if most entries in the column are empty. In our dataset, none of the columns are empty enough to drop entirely. We have some freedom in choosing which method to replace data; however, some methods may seem more reasonable than others. We will apply each method to many different columns:\n",
        "\n",
        "Replace by mean:\n",
        "\n",
        "    \"normalized-losses\": 41 missing data, replace them with mean\n",
        "    \"stroke\": 4 missing data, replace them with mean\n",
        "    \"bore\": 4 missing data, replace them with mean\n",
        "    \"horsepower\": 2 missing data, replace them with mean\n",
        "    \"peak-rpm\": 2 missing data, replace them with mean\n",
        "\n",
        "Replace by frequency:\n",
        "\n",
        "    \"num-of-doors\": 2 missing data, replace them with \"four\".\n",
        "        Reason: 84% sedans is four doors. Since four doors is most frequent, it is most likely to occur\n",
        "\n",
        "Drop the whole row:\n",
        "\n",
        "    \"price\": 4 missing data, simply delete the whole row\n",
        "        Reason: price is what we want to predict. Any data entry without price data cannot be used for prediction; therefore any row now without price data is not useful to us\n",
        "\n"
      ],
      "metadata": {
        "id": "XNGoxN2eK9af"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicando las tareas por hacer\n",
        "\n",
        "# reemplazando los nan de avg_norm_loss por su media\n",
        "avg_norm_loss = df[\"normalized-losses\"].astype(\"float\").mean(axis=0)\n",
        "print(\"Average of normalized-losses:\", avg_norm_loss)\n",
        "df[\"normalized-losses\"].replace(np.nan, avg_norm_loss, inplace=True)\n",
        "\n",
        "# reemplazando los nan de bore por su media\n",
        "avg_bore=df['bore'].astype('float').mean(axis=0)\n",
        "print(\"Average of bore:\", avg_bore)\n",
        "df[\"bore\"].replace(np.nan, avg_bore, inplace=True)\n",
        "\n",
        "# reemplazando los nan de \"stroke\" por su media \n",
        "avg_stroke = df[\"stroke\"].astype(\"float\").mean(axis = 0)\n",
        "print(\"Average of stroke:\", avg_stroke)\n",
        "df[\"stroke\"].replace(np.nan, avg_stroke, inplace = True)\n",
        "\n",
        "# reemplazando los nan de horsepower por su media\n",
        "avg_horsepower = df['horsepower'].astype('float').mean(axis=0)\n",
        "print(\"Average horsepower:\", avg_horsepower)\n",
        "df['horsepower'].replace(np.nan, avg_horsepower, inplace=True)\n",
        "\n",
        "# reemplazando los nan de peak-rpm por su media\n",
        "avg_peakrpm=df['peak-rpm'].astype('float').mean(axis=0)\n",
        "print(\"Average peak rpm:\", avg_peakrpm)\n",
        "df['peak-rpm'].replace(np.nan, avg_peakrpm, inplace=True)\n",
        "\n",
        "\n",
        "# Para el caso de Num of doors por el análisis emprico ya que solo hay 2 opciones de manera general en la industria:\n",
        "\n",
        "#vemos cuantos valores hay, luego de esos cual es el maximo\n",
        "print(\"\")\n",
        "print(df['num-of-doors'].value_counts())\n",
        "print(df['num-of-doors'].value_counts().idxmax())\n",
        "print(\"\")\n",
        "\n",
        "# reemplazando los nan de \"num-of-doors por el valor mas repetido que es \"four\"\n",
        "\n",
        "#df[\"num-of-doors\"].replace(np.nan, \"four\", inplace=True)\n",
        "\n",
        "#mejor:\n",
        "\n",
        "df[\"num-of-doors\"].replace(np.nan, \n",
        "                           str(df['num-of-doors'].value_counts().idxmax()), \n",
        "                           inplace=True)\n",
        "\n",
        "# simply drop whole row with NaN in \"price\" column\n",
        "df.dropna(subset=[\"price\"], axis=0, inplace=True)\n",
        "\n",
        "# reset index, because we droped two rows\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "MqFzL4qdK-V1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***********************************\n",
        "Corrigiendo el formato:"
      ],
      "metadata": {
        "id": "IT_0WbDiLDVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#antes de la transformación\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "E90Hg-VHLEib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformando\n",
        "df[[\"bore\", \"stroke\",\"price\",\"peak-rpm\"]] =  df[[\"bore\", \"stroke\",\"price\",\"peak-rpm\"]].astype(\"float\")\n",
        "df[[\"normalized-losses\"]] = df[[\"normalized-losses\"]].astype(\"int\")"
      ],
      "metadata": {
        "id": "PZEYgwt4LGQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#despues de la transformación\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "l5Yc7k-MLIiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "****************************************************************************************************************************************\n",
        "\n",
        "Data Standardization\n",
        "\n",
        "La estandarización es el proceso de transformar los datos en un formato común, lo que permite al investigador hacer una comparación significativa.\n",
        "\n",
        "\n",
        "en este ejemplo, lo convierte a unidades mas entendibles por el investifador\n",
        "\n",
        "mpg to L/100km: L/100km = 235 / mpg o vicecersa para el caso de la pregunta"
      ],
      "metadata": {
        "id": "D1KKf_C8LLp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert mpg to L/100km by mathematical operation (235 divided by mpg)\n",
        "df['city-L/100km'] = 235/df[\"city-mpg\"]\n",
        "\n",
        "# check your transformed data \n",
        "df.head()"
      ],
      "metadata": {
        "id": "0rZme1U9LPaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transform mpg to L/100km by mathematical operation (235 divided by mpg)\n",
        "df[\"highway-mpg\"] = 235/df[\"highway-mpg\"]\n",
        "\n",
        "# rename column name from \"highway-mpg\" to \"highway-L/100km\"\n",
        "df.rename(columns={'highway-mpg':'highway-L/100km'}, inplace=True)\n",
        "\n",
        "# check your transformed data \n",
        "df.head()"
      ],
      "metadata": {
        "id": "sMcqVJVhLQxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "******************\n",
        "Data Normalization"
      ],
      "metadata": {
        "id": "DNrvM-MYLVSv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Igualar el ranfo de variables que sean muy dispares. \n",
        "\n",
        "Normalmente con media 0, y varianza 1, o rango entre 0 y 1. \n",
        "\n",
        "para este ejemplo, normaliza las columnas \"length\", \"width\" and \"height\""
      ],
      "metadata": {
        "id": "Bf3iRWyaLWdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# replace (original value) by (original value)/(maximum value)\n",
        "df['length'] = df['length']/df['length'].max()\n",
        "df['width'] = df['width']/df['width'].max()\n",
        "df['height'] = df['height']/df['height'].max() \n",
        "\n",
        "# show the scaled columns\n",
        "df[[\"length\",\"width\",\"height\"]].head()"
      ],
      "metadata": {
        "id": "iVhkxzfjLS1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "********************\n",
        "Binning\n"
      ],
      "metadata": {
        "id": "pSifDmS3Las_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Binning es el proceso de transformar variables continuas numericas en categóricas o 'bins' para hacer análisis agrupandolas.   \n",
        "\n",
        "en el ejemplo, \"horsepower\" tiene valores entre 48 y 288 con 59 valores unicos. \n",
        "\n",
        "en el supuesto caso de que nos interese el precio dado las categorías: \n",
        "1.- high horsepower\n",
        "2.- medium horsepower\n",
        "3.- little horsepower \n",
        "\n",
        "se puede usar linspace(start_value, end_value, numbers_generated y  pd.cut() para crear esos bins"
      ],
      "metadata": {
        "id": "2VVGQbkSLcB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"horsepower\"]=df[\"horsepower\"].astype(int, copy=True)"
      ],
      "metadata": {
        "id": "n4y2CIOQLeWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib as plt\n",
        "from matplotlib import pyplot\n",
        "plt.pyplot.hist(df[\"horsepower\"])\n",
        "\n",
        "# set x/y labels and plot title\n",
        "plt.pyplot.xlabel(\"horsepower\")\n",
        "plt.pyplot.ylabel(\"count\")\n",
        "plt.pyplot.title(\"horsepower bins\")"
      ],
      "metadata": {
        "id": "NViSwdTILho4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creando los bins, con valor min y val max de la columna y 4 \n",
        "bins = np.linspace(min(df[\"horsepower\"]), max(df[\"horsepower\"]), 4)\n",
        "#nombres de las categorias\n",
        "group_names = ['Low', 'Medium', 'High']\n",
        "#usando cut en la nueva col para crear la nueva variable con bin\n",
        "df['horsepower-binned'] = pd.cut(df['horsepower'], bins, labels=group_names, include_lowest=True )\n",
        "df[['horsepower','horsepower-binned']].head(20)"
      ],
      "metadata": {
        "id": "GsZEtALrLjpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"horsepower-binned\"].value_counts()"
      ],
      "metadata": {
        "id": "0bRs4AxULlUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "pyplot.bar(group_names, df[\"horsepower-binned\"].value_counts())\n",
        "\n",
        "# set x/y labels and plot title\n",
        "plt.pyplot.xlabel(\"horsepower\")\n",
        "plt.pyplot.ylabel(\"count\")\n",
        "plt.pyplot.title(\"horsepower bins\")\n"
      ],
      "metadata": {
        "id": "NO6Y-_GSLmsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "# draw historgram of attribute \"horsepower\" with bins = 3\n",
        "plt.pyplot.hist(df[\"horsepower\"], bins = 3)\n",
        "\n",
        "# set x/y labels and plot title\n",
        "plt.pyplot.xlabel(\"horsepower\")\n",
        "plt.pyplot.ylabel(\"count\")\n",
        "plt.pyplot.title(\"horsepower bins\")"
      ],
      "metadata": {
        "id": "RAJR-IXDLoiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***********************\n",
        "Indicator Variable (or Dummy Variable)"
      ],
      "metadata": {
        "id": "IGJMH7gwLqlv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uso de variables numericas para representar variables categóricas ya que usualmente los modelos no son capaces de usar variables categóricas\n",
        "\n",
        "en este ejemplo:\n",
        "\n",
        " \"fuel-type\" tiene dos valres: \"gas\" or \"diesel\". \n",
        " \n",
        "una Regresion solo acepta numeros como parametros de entrada asi que lo convertiremos a numérico.\n",
        "\n",
        "se usa:  pd.get_dummies(col)\n",
        "\n",
        "lo mismo para las columnas: aspiration\n",
        " \n",
        " "
      ],
      "metadata": {
        "id": "2u3mPKfKLsE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creando los dummies para la variable 1\n",
        "\n",
        "\n",
        "dummy_variable_1 = pd.get_dummies(df[\"fuel-type\"])\n",
        "#para facilidad renombra esas variables \n",
        "dummy_variable_1.rename(columns={'gas':'fuel-type-gas', 'diesel':'fuel-type-diesel'}, inplace=True)\n",
        "# uniendolas\n",
        "df = pd.concat([df, dummy_variable_1], axis=1)\n",
        "\n",
        "# se elimina la col original\n",
        "df.drop(\"fuel-type\", axis = 1, inplace=True)\n",
        "\n",
        "\n",
        "#creando los dummies para la variable 2\n",
        "\n",
        "\n",
        "dummy_variable_2 = pd.get_dummies(df['aspiration'])\n",
        "dummy_variable_2.rename(columns={'std':'aspiration-std', 'turbo': 'aspiration-turbo'}, inplace=True)\n",
        "df = pd.concat([df, dummy_variable_2], axis=1)\n",
        "df.drop('aspiration', axis = 1, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "5XLnXHj9Luzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicando la misma lógica para la variable agrpada de gasolinas.\n",
        "\n",
        "dummy_variable_3 = pd.get_dummies(df['horsepower-binned'])\n",
        "dummy_variable_3.rename(columns={'Low':'gas-low', 'Medium': 'gas-medium', 'High':'gas-high'}, inplace=True)\n",
        "df = pd.concat([df, dummy_variable_3], axis=1)\n",
        "df.drop('horsepower-binned', axis = 1, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "AU0Hi-tdLwxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "ZyArzYz3LzNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "8TWerMF9L1dP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}